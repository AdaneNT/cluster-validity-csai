{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a803f836",
   "metadata": {},
   "source": [
    "# CSAIEvaluator Demo with AG News Dataset\n",
    "This notebook demonstrates how to use the CSAIEvaluator for evaluating clustering stability using the AG News dataset.\n",
    "We use SBERT for embeddings, UMAP for dimensionality reduction, and KMeans for clustering."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a2f5e375",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import warnings\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sentence_transformers import SentenceTransformer\n",
    "import umap\n",
    "from csai import CSAIEvaluator\n",
    "\n",
    "# Suppress UMAP warnings\n",
    "warnings.filterwarnings(\"ignore\", message=\"n_jobs value 1 overridden to 1 by setting random_state*\", category=UserWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e19b2c59",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sbert_embeddings(texts):\n",
    "    model = SentenceTransformer(\"all-MiniLM-L6-v2\")\n",
    "    return model.encode(texts, convert_to_tensor=False)\n",
    "\n",
    "def reduce_with_umap(df, emb_col=\"SBERT_Embedding\", output_col=\"key_umap\", n_components=10):\n",
    "    reducer = umap.UMAP(n_components=n_components, random_state=42)\n",
    "    emb_array = np.array(df[emb_col].tolist())\n",
    "    reduced = reducer.fit_transform(emb_array)\n",
    "    df[output_col] = reduced.tolist()\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0e6dbf9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import fetch_20newsgroups\n",
    "\n",
    "def run_pipeline():\n",
    "    newsgroups = fetch_20newsgroups(subset='all')\n",
    "    df = pd.DataFrame(newsgroups.data, columns=[\"text\"])\n",
    "    df = df.sample(n=5000, random_state=42).reset_index(drop=True)\n",
    "\n",
    "    texts = df[\"text\"].fillna(\"\").apply(lambda x: re.sub(r\"\\d+|[^\\w\\s]|\\s+\", \" \", x.lower()).strip()).tolist()\n",
    "\n",
    "    embeddings = get_sbert_embeddings(texts)\n",
    "    df[\"SBERT_Embedding\"] = embeddings.tolist()\n",
    "\n",
    "    df = reduce_with_umap(df, emb_col=\"SBERT_Embedding\", output_col=\"key_umap\", n_components=10)\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c43d02fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "OMP: Info #276: omp_set_nested routine deprecated, please use omp_set_max_active_levels instead.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "((3500, 3), (1500, 3))"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Split the data into train and test sets\n",
    "df_processed = run_pipeline()\n",
    "X_train, X_test = train_test_split(df_processed, test_size=0.3, random_state=42)\n",
    "X_train.shape, X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "928f7d7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a  clustering label function (e.g KMeans)\n",
    "def kmeans_label_func(embeddings, n_clusters=6):\n",
    "    model = KMeans(n_clusters=n_clusters, random_state=42)\n",
    "    labels = model.fit_predict(embeddings)\n",
    "    return labels, model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ff48ca94",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample 1 | CSAI per cluster: [0.0917, 0.0726, 0.3792, 0.0599, 0.151, 0.3071] |  CSAI across all clusters: 0.1769\n",
      "Sample 2 | CSAI per cluster: [0.4007, 0.5892, 0.6028, 0.1161, 0.5832, 0.0527] |  CSAI across all clusters: 0.3908\n",
      "Sample 3 | CSAI per cluster: [0.0427, 0.2734, 0.1875, 0.1537, 0.5796, 0.0077] |  CSAI across all clusters: 0.2074\n",
      "Sample 4 | CSAI per cluster: [0.4103, 0.2025, 0.3228, 0.1819, 0.0501, 0.0581] |  CSAI across all clusters: 0.2043\n",
      "Sample 5 | CSAI per cluster: [0.1667, 0.3858, 0.2506, 0.3021, 0.1931, 0.1928] |  CSAI across all clusters: 0.2485\n",
      "\n",
      "Overall CSAI across all samples: 0.2456\n",
      "\n",
      "CSAIEvaluator Score: 0.24558853084328952\n"
     ]
    }
   ],
   "source": [
    "# Evaluate with CSAIEvaluator\n",
    "csai = CSAIEvaluator()\n",
    "score = csai.run_csai_evaluation(\n",
    "    X_train, X_test,\n",
    "    key_col=\"key_umap\",\n",
    "    label_func=kmeans_label_func,\n",
    "    n_splits=5\n",
    ")\n",
    "print(\"\\nCSAIEvaluator Score:\", score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05257689-4b10-4c5f-89de-65eadd67a15c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
